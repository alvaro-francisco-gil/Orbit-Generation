{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "> Scripts to build the different datasets used for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple, Optional, List, Dict\n",
    "from orbit_generation.data import load_orbit_data, get_orbit_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exact Periods with Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All 5 periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_5p_em_dataset(data_directory: Optional[str] = '../data', \n",
    "                      output_file_path: Optional[str] = '../data/5p_dataset_em.npy') -> Tuple[np.memmap, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Load orbit data and corresponding labels. Optionally, save the loaded data.\n",
    "    If the output file exists, return the data as a memory-mapped array, otherwise process and save the data.\n",
    "    After saving, the data is also returned as a memory-mapped array.\n",
    "    \"\"\"\n",
    "    # Extract file extension to determine the type\n",
    "    _, file_extension = os.path.splitext(output_file_path)\n",
    "\n",
    "    # Validate supported file types\n",
    "    if file_extension not in ['.hdf5', '.npy']:\n",
    "        raise ValueError(\"Unsupported file extension. Supported extensions are '.hdf5' or '.npy'.\")\n",
    "\n",
    "    # Define the path for labels file\n",
    "    labels_path = f\"{os.path.splitext(output_file_path)[0]}_labels.npy\"\n",
    "\n",
    "    # Check if the combined data file already exists\n",
    "    if os.path.exists(output_file_path):\n",
    "        # Load data as memmap\n",
    "        data_memmap = np.load(output_file_path, mmap_mode='r+') if file_extension == '.npy' else None  # Add hdf5 handling if needed\n",
    "        labels_memmap = np.load(labels_path)\n",
    "        return data_memmap, labels_memmap\n",
    "\n",
    "    # Paths to data files\n",
    "    orbits_file_path = os.path.join(data_directory, \"em_orbits.h5\")\n",
    "    features_file_path = os.path.join(data_directory, \"em_features.mat\")\n",
    "\n",
    "    # Load orbit labels\n",
    "    labels_df = get_orbit_features(features_file_path, variable_name='out_EM') \n",
    "    labels = pd.Series(labels_df['Orbit Family']).repeat(5).reset_index(drop=True).to_numpy()\n",
    "\n",
    "    # Load orbit data\n",
    "    orbit_data = load_orbit_data(orbits_file_path, dataset_path='/files/PERIODIC ORBITS')\n",
    "    reshaped_array = orbit_data.reshape(36071, 7, 5, 1500)\n",
    "    orbit_data_final = reshaped_array.transpose(0, 2, 1, 3).reshape(36071 * 5, 7, 1500)\n",
    "\n",
    "    # Save the data if an output file path is provided\n",
    "    if file_extension == '.npy':\n",
    "        np.save(output_file_path, orbit_data_final)\n",
    "        np.save(labels_path, labels)\n",
    "        data_memmap = np.load(output_file_path, mmap_mode='r+')\n",
    "\n",
    "    return data_memmap, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_1p_em_dataset(data_directory: Optional[str] = '../data',\n",
    "                      output_file_path: Optional[str] = '../data/1p_dataset_em.npy') -> Tuple[np.memmap, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Load orbit data from an HDF5 file and corresponding labels from a MAT file, and optionally save the loaded data.\n",
    "    If the output file exists, it returns the data as a memory-mapped array. After saving, the data is also returned as a memory-mapped array.\n",
    "    \"\"\"\n",
    "    # Extract file extension to determine the type\n",
    "    _, file_extension = os.path.splitext(output_file_path)\n",
    "\n",
    "    # Validate supported file types\n",
    "    if file_extension not in ['.hdf5', '.npy']:\n",
    "        raise ValueError(\"Unsupported file extension. Supported extensions are '.hdf5' or '.npy'.\")\n",
    "\n",
    "    # Define the path for labels file\n",
    "    labels_path = f\"{os.path.splitext(output_file_path)[0]}_labels.npy\"\n",
    "\n",
    "    # Check if the combined data file already exists\n",
    "    if os.path.exists(output_file_path):\n",
    "        data_memmap = np.load(output_file_path, mmap_mode='r+') if file_extension == '.npy' else None\n",
    "        labels_memmap = np.load(labels_path)\n",
    "        return data_memmap, labels_memmap\n",
    "\n",
    "    # Paths to data files\n",
    "    orbits_file_path = os.path.join(data_directory, \"em_orbits.h5\")\n",
    "    features_file_path = os.path.join(data_directory, \"em_features.mat\")\n",
    "\n",
    "    # Load orbit labels\n",
    "    labels_df = get_orbit_features(features_file_path, variable_name='out_EM') \n",
    "    labels = labels_df['Orbit Family'].to_numpy()\n",
    "\n",
    "    # Load orbit data\n",
    "    orbit_data = load_orbit_data(orbits_file_path, dataset_path='/files/PERIODIC ORBITS')\n",
    "    reshaped_orbit_data = orbit_data[:, :, :1500]\n",
    "\n",
    "    # Save the data if an output file path is provided\n",
    "    if file_extension == '.npy':\n",
    "        np.save(output_file_path, reshaped_orbit_data)\n",
    "        np.save(labels_path, labels)\n",
    "        data_memmap = np.load(output_file_path, mmap_mode='r+')\n",
    "\n",
    "    return data_memmap, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific Period for each Orbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_sp_em_dataset(data_directory: Optional[str] = '../data', \n",
    "                      output_file_path: Optional[str] = '../data/sp_dataset_em.npy') -> Tuple[np.memmap, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Load orbit data and corresponding labels based on the specified number of periods per orbit.\n",
    "    If the output file exists, return the data as a memory-mapped array, otherwise process and save the data.\n",
    "    After saving, the data is also returned as a memory-mapped array.\n",
    "    \"\"\"\n",
    "    # Extract file extension to determine the type\n",
    "    _, file_extension = os.path.splitext(output_file_path)\n",
    "\n",
    "    # Validate supported file types\n",
    "    if file_extension not in ['.hdf5', '.npy']:\n",
    "        raise ValueError(\"Unsupported file extension. Supported extensions are '.hdf5' or '.npy'.\")\n",
    "\n",
    "    # Define the path for labels file\n",
    "    labels_path = f\"{os.path.splitext(output_file_path)[0]}_labels.npy\"\n",
    "\n",
    "    # Check if the combined data file already exists\n",
    "    if os.path.exists(output_file_path):\n",
    "        data_memmap = np.load(output_file_path, mmap_mode='r+') if file_extension == '.npy' else None\n",
    "        labels_memmap = np.load(labels_path)\n",
    "        return data_memmap, labels_memmap\n",
    "\n",
    "    # Paths to data files\n",
    "    orbits_file_path = os.path.join(data_directory, \"em_orbits.h5\")\n",
    "    features_file_path = os.path.join(data_directory, \"em_features.mat\")\n",
    "    periods_file_path = os.path.join(data_directory, \"em_periods.npy\")\n",
    "\n",
    "    # Load orbit labels\n",
    "    labels_df = get_orbit_features(features_file_path, variable_name='out_EM') \n",
    "    labels = labels_df['Orbit Family'].to_numpy()\n",
    "\n",
    "    # Load number of periods per orbit\n",
    "    periods_per_orbit = np.load(periods_file_path)\n",
    "\n",
    "    # Load orbit data\n",
    "    with h5py.File(orbits_file_path, 'r') as file:\n",
    "        orbit_data = np.array(file['/files/PERIODIC ORBITS'])\n",
    "\n",
    "    # Initialize the result array and label list\n",
    "    orbit_data_final = []\n",
    "    final_labels = []\n",
    "\n",
    "    # Iterate over the orbits and periods array\n",
    "    for index, num_periods in enumerate(periods_per_orbit):\n",
    "        for period_idx in range(num_periods):\n",
    "            start_idx = 1500 * period_idx\n",
    "            end_idx = start_idx + 1500\n",
    "            orbit_slice = orbit_data[index, :, start_idx:end_idx]\n",
    "            orbit_data_final.append(orbit_slice)\n",
    "            final_labels.append(labels[index])\n",
    "\n",
    "    # Convert list to numpy array\n",
    "    orbit_data_final = np.stack(orbit_data_final)  # This ensures a uniform 3D array\n",
    "\n",
    "    # Save the data if an output file path is provided\n",
    "    if file_extension == '.npy':\n",
    "        np.save(output_file_path, orbit_data_final)\n",
    "        np.save(labels_path, final_labels)\n",
    "        data_memmap = np.load(output_file_path, mmap_mode='r+')\n",
    "        final_labels = np.load(labels_path)\n",
    "\n",
    "    return data_memmap, final_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data, labels = get_sp_em_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixed time step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific Period for each Orbit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "include labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_sp_fixed_em_dataset(data_directory: Optional[str] = '../data', \n",
    "                            output_data_path: Optional[str] = '../data/em_periods.npy', \n",
    "                            output_periods_path: Optional[str] = '../data/em_periods.npy') -> Tuple[Dict[int, np.ndarray], np.ndarray]:\n",
    "    \"\"\"\n",
    "    Load orbit data from an HDF5 file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the default data directory based on the script's location if not provided\n",
    "    if data_directory is None:\n",
    "        data_directory = os.path.join(os.path.dirname(__file__), \"Data\")\n",
    "    \n",
    "    # Define the file path for the orbit data\n",
    "    file_path = os.path.join(data_directory, \"em_orbits_dt_0_01.h5\")\n",
    "    \n",
    "    # Initialize a dictionary to hold data from all datasets\n",
    "    orbit_data = {}\n",
    "    \n",
    "    # Open the HDF5 file and read data from each dataset\n",
    "    with h5py.File(file_path, 'r') as file:\n",
    "        # Iterate through each dataset in the HDF5 file\n",
    "        for name in file:\n",
    "            dataset = np.array(file[name])\n",
    "            if name.isdigit():\n",
    "                orbit_data[int(name)] = dataset\n",
    "            else:\n",
    "                orbit_data[name] = dataset\n",
    "    \n",
    "    # Extract the periods\n",
    "    periods = orbit_data.get('prop_periods')[0] if 'prop_periods' in orbit_data else None\n",
    "\n",
    "    # Save the entire orbit data if an output path is provided\n",
    "    if output_data_path:\n",
    "        if output_data_path.endswith('.npy'):\n",
    "            np.save(output_data_path, orbit_data)\n",
    "        elif output_data_path.endswith('.h5'):\n",
    "            with h5py.File(output_data_path, 'w') as h5_file:\n",
    "                for key, data in orbit_data.items():\n",
    "                    h5_file.create_dataset(key, data=data)\n",
    "\n",
    "    # Save periods data if an output path is provided\n",
    "    if output_periods_path:\n",
    "        if output_periods_path.endswith('.npy'):\n",
    "            np.save(output_periods_path, periods)\n",
    "        elif output_periods_path.endswith('.h5'):\n",
    "            with h5py.File(output_periods_path, 'w') as h5_file:\n",
    "                h5_file.create_dataset('periods', data=periods)\n",
    "\n",
    "    return orbit_data, periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_orbit_data_from_hdf5(file_path: str                  # Path to the HDF5 file.\n",
    "                         ) -> Tuple[Dict[int, np.ndarray],   # Dictionary of orbits with numerical keys.\n",
    "                                    pd.DataFrame,            # DataFrame containing orbit features.\n",
    "                                    Dict[str, float]]:       # Dictionary containing system features.\n",
    "    \"\"\"\n",
    "    Load orbit data from an HDF5 file.\n",
    "    \"\"\"\n",
    "    with h5py.File(file_path, 'r') as file:\n",
    "        # Extract not_propagated_orbits and store in a list of integers\n",
    "        not_propagated_orbits = [index - 1 for index in file['not_propagated_orbits'][0].tolist()]\n",
    "        \n",
    "        # Extract system features and labels\n",
    "        system_features = file['system_features'][:]\n",
    "        system_labels = file['system_labels'][:].astype(str)\n",
    "        \n",
    "        # Create a dictionary for system\n",
    "        system_dict = {label: feature[0] for label, feature in zip(system_labels.flatten().tolist(), system_features)}\n",
    "        \n",
    "        # Extract orbit features and labels\n",
    "        orbit_features = file['orbit_features'][:]\n",
    "        orbit_labels = file['orbit_labels'][:].astype(str)\n",
    "        \n",
    "        # Create a dataframe for orbits\n",
    "        orbit_df = pd.DataFrame(orbit_features.T, columns=orbit_labels.flatten().tolist())\n",
    "        \n",
    "        # Remove rows in orbit_df based on not_propagated_orbits\n",
    "        orbit_df = orbit_df.drop(not_propagated_orbits).reset_index(drop=True)\n",
    "        \n",
    "        # Extract numpy arrays with numerical keys\n",
    "        orbits = {int(key): file[key][:] for key in file.keys() if key.isdigit()}\n",
    "        \n",
    "        # Reset the index of the dictionary to start on 0\n",
    "        orbits = {i: orbits[key] for i, key in enumerate(sorted(orbits.keys()))}\n",
    "                \n",
    "    return orbits, orbit_df, system_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_time_vector_to_orbits(orbits: Dict[int, np.ndarray],  # Dictionary of orbits with numerical keys.\n",
    "                              orbits_df: pd.DataFrame         # DataFrame containing orbit features.\n",
    "                             ) -> Dict[int, np.ndarray]:      # Dictionary of updated orbits with time vectors added.\n",
    "    \"\"\"\n",
    "    Add a time vector to each orbit in the dictionary.\n",
    "    \"\"\"\n",
    "    # Create a new dictionary to store the updated orbits\n",
    "    updated_orbits = {}\n",
    "\n",
    "    # Iterate over each orbit in the dictionary\n",
    "    for key, orbit in orbits.items():\n",
    "        # Get the corresponding row from the dataframe\n",
    "        orbit_row = orbits_df.loc[int(key)]\n",
    "\n",
    "        # Extract the propagated_periods and period for this orbit\n",
    "        propagated_periods = orbit_row['propagated_periods']\n",
    "        period = orbit_row['period']\n",
    "\n",
    "        # Compute the new time vector\n",
    "        tvec = np.linspace(0, propagated_periods * period, orbit.shape[1])\n",
    "\n",
    "        # Add the time vector as the first vector in the orbit array\n",
    "        updated_orbit = np.vstack([tvec, orbit])\n",
    "\n",
    "        # Add the updated orbit to the new dictionary\n",
    "        updated_orbits[key] = updated_orbit\n",
    "\n",
    "    return updated_orbits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_and_convert_to_3d(orbits: Dict[int, np.ndarray],     # Dictionary of orbits with numerical keys.\n",
    "                          timesteps: int                     # Desired number of timesteps.\n",
    "                         ) -> np.ndarray:                    # 3D numpy array of padded orbits.\n",
    "    \"\"\"\n",
    "    Truncate and pad each orbit to a uniform length and convert to a 3D numpy array.\n",
    "    \"\"\"\n",
    "    # Initialize a list to store the padded arrays\n",
    "    padded_arrays = []\n",
    "\n",
    "    # Iterate over each orbit in the dictionary\n",
    "    for key, orbit in orbits.items():\n",
    "        # Determine the number of timesteps to take from the orbit\n",
    "        num_timesteps = min(timesteps, orbit.shape[1])\n",
    "\n",
    "        # Take the first num_timesteps from the orbit\n",
    "        truncated_orbit = orbit[:, :num_timesteps]\n",
    "\n",
    "        # Pad the truncated orbit to have length timesteps in the final dimension\n",
    "        padded_orbit = np.pad(truncated_orbit, ((0, 0), (0, timesteps - num_timesteps)))\n",
    "\n",
    "        # Add the padded orbit to the list\n",
    "        padded_arrays.append(padded_orbit)\n",
    "\n",
    "    # Convert the list of padded arrays to a 3D numpy array and return it\n",
    "    return np.stack(padded_arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_and_convert_to_3d(orbits: Dict[int, np.ndarray],  # Dictionary of orbits with numerical keys.\n",
    "                              segment_length: int             # Desired length of each segment.\n",
    "                             ) -> Tuple[np.ndarray,           # 3D numpy array of segments.\n",
    "                                        List[int]]:           # List of IDs representing each new segment.\n",
    "    \"\"\"\n",
    "    Divide each orbit into segments of a given length and convert to a 3D numpy array.\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    \n",
    "    # Initialize a list to store the segments and their corresponding IDs\n",
    "    segments = []\n",
    "    segment_ids = []\n",
    "\n",
    "    # Iterate over each orbit in the dictionary\n",
    "    for key, orbit in orbits.items():\n",
    "        # Determine the number of complete segments that can be taken from the orbit\n",
    "        num_segments = orbit.shape[1] // segment_length\n",
    "\n",
    "        # Iterate over the number of complete segments\n",
    "        for i in range(num_segments):\n",
    "            # Take the segment of the desired length\n",
    "            segment = orbit[:, i*segment_length:(i+1)*segment_length]\n",
    "\n",
    "            # Add the segment to the list\n",
    "            segments.append(segment)\n",
    "\n",
    "            # Add the corresponding ID to the list\n",
    "            segment_ids.append(key)\n",
    "\n",
    "    # Convert the list of segments to a 3D numpy array\n",
    "    segments_3d = np.stack(segments)\n",
    "\n",
    "    return segments_3d, segment_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_first_period_dataset(file_path):\n",
    "    \n",
    "    orbits, orbit_df, system_dict = get_orbit_data_from_hdf5(file_path)\n",
    "\n",
    "    file_parts = os.path.basename(file_path).split('_')\n",
    "\n",
    "    if file_parts[1] == 'N':\n",
    "        orbits = add_time_vector_to_orbits(orbits, orbit_df)\n",
    "        orbits = pad_and_convert_to_3d(orbits, file_parts[3])\n",
    "    \n",
    "    else:\n",
    "        \n",
    "\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'your_file.hdf5' with the path to your .hdf5 file\n",
    "file_path = '/orbit-generation/data/orbits_dt_0_01/EM_dt_fix_0_01.h5'\n",
    "orbits, orbit_df, system_dict = get_orbit_data_from_hdf5(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '/orbit-generation/data/orbits_fix_1500/EM_N_fix_1500.h5'\n",
    "orbits, orbit_df, system_dict = get_orbit_data_from_hdf5(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_orbits = add_time_vector_to_orbits(orbits, orbit_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45211"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(orbits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "678165"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "45211*15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "orbit=orbits[1622]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 7496)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orbit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented_orbits, orbits_ids = segment_and_convert_to_3d(updated_orbits,1499)\n",
    "segmented_orbits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'orbit_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43morbit_labels\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'orbit_labels' is not defined"
     ]
    }
   ],
   "source": [
    "orbit_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from orbit_generation.propagation import calculate_errors\n",
    "from orbit_generation.constants import MU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid orbit_data shape. Must be (n, 6, m) or (n, 7, m)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m errors \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_errors\u001b[49m\u001b[43m(\u001b[49m\u001b[43morbit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMU\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime_step\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/orbit_generation/propagation.py:223\u001b[0m, in \u001b[0;36mcalculate_errors\u001b[0;34m(orbit_data, mu, orbit_indices, error_types, time_step, display_results)\u001b[0m\n\u001b[1;32m    221\u001b[0m     orbit_data \u001b[38;5;241m=\u001b[39m orbit_data_with_time\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m orbit_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m7\u001b[39m:\n\u001b[0;32m--> 223\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid orbit_data shape. Must be (n, 6, m) or (n, 7, m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    225\u001b[0m num_time_points \u001b[38;5;241m=\u001b[39m orbit_data\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    226\u001b[0m tvec \u001b[38;5;241m=\u001b[39m orbit_data[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# Time vector from the data\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid orbit_data shape. Must be (n, 6, m) or (n, 7, m)"
     ]
    }
   ],
   "source": [
    "errors = calculate_errors(orbit, MU, time_step=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_class</th>\n",
       "      <th>x_0</th>\n",
       "      <th>y_0</th>\n",
       "      <th>x_0</th>\n",
       "      <th>vx_0</th>\n",
       "      <th>vy_0</th>\n",
       "      <th>vz_0</th>\n",
       "      <th>jacobi</th>\n",
       "      <th>period</th>\n",
       "      <th>stability</th>\n",
       "      <th>propagated_periods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.941000</td>\n",
       "      <td>1.900442e-23</td>\n",
       "      <td>0.509474</td>\n",
       "      <td>2.968938e-13</td>\n",
       "      <td>-0.124968</td>\n",
       "      <td>-3.122717e-12</td>\n",
       "      <td>2.745412</td>\n",
       "      <td>11.555291</td>\n",
       "      <td>211.184678</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.941538</td>\n",
       "      <td>-8.592698e-24</td>\n",
       "      <td>0.508602</td>\n",
       "      <td>2.902340e-13</td>\n",
       "      <td>-0.125672</td>\n",
       "      <td>-3.252212e-12</td>\n",
       "      <td>2.746226</td>\n",
       "      <td>11.551622</td>\n",
       "      <td>210.329145</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.942076</td>\n",
       "      <td>6.956604e-24</td>\n",
       "      <td>0.507729</td>\n",
       "      <td>2.685527e-13</td>\n",
       "      <td>-0.126375</td>\n",
       "      <td>-2.862050e-12</td>\n",
       "      <td>2.747039</td>\n",
       "      <td>11.547936</td>\n",
       "      <td>209.473685</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.942613</td>\n",
       "      <td>1.763946e-24</td>\n",
       "      <td>0.506856</td>\n",
       "      <td>3.153637e-13</td>\n",
       "      <td>-0.127078</td>\n",
       "      <td>-3.791054e-12</td>\n",
       "      <td>2.747850</td>\n",
       "      <td>11.544233</td>\n",
       "      <td>208.618315</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.943150</td>\n",
       "      <td>9.441804e-24</td>\n",
       "      <td>0.505982</td>\n",
       "      <td>2.663322e-13</td>\n",
       "      <td>-0.127781</td>\n",
       "      <td>-2.982720e-12</td>\n",
       "      <td>2.748660</td>\n",
       "      <td>11.540511</td>\n",
       "      <td>207.763051</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_class       x_0           y_0       x_0          vx_0      vy_0  \\\n",
       "0       1.0  0.941000  1.900442e-23  0.509474  2.968938e-13 -0.124968   \n",
       "1       1.0  0.941538 -8.592698e-24  0.508602  2.902340e-13 -0.125672   \n",
       "2       1.0  0.942076  6.956604e-24  0.507729  2.685527e-13 -0.126375   \n",
       "3       1.0  0.942613  1.763946e-24  0.506856  3.153637e-13 -0.127078   \n",
       "4       1.0  0.943150  9.441804e-24  0.505982  2.663322e-13 -0.127781   \n",
       "\n",
       "           vz_0    jacobi     period   stability  propagated_periods  \n",
       "0 -3.122717e-12  2.745412  11.555291  211.184678                 3.0  \n",
       "1 -3.252212e-12  2.746226  11.551622  210.329145                 3.0  \n",
       "2 -2.862050e-12  2.747039  11.547936  209.473685                 3.0  \n",
       "3 -3.791054e-12  2.747850  11.544233  208.618315                 3.0  \n",
       "4 -2.982720e-12  2.748660  11.540511  207.763051                 3.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orbit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45211, 11)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orbit_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39817"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(orbits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mu': 0.01215058560962404,\n",
       " 'LU': 389703.0,\n",
       " 'TU': 382981.0,\n",
       " 'VU': 1.0175517845532807,\n",
       " 'Lx1': 0.8369151257723573,\n",
       " 'Ly1': 0.0,\n",
       " 'Lx2': 1.1556821654448846,\n",
       " 'Ly2': 0.0,\n",
       " 'Lx3': -1.005062645810278,\n",
       " 'Ly3': 0.0,\n",
       " 'Lx4': 0.48784941439037594,\n",
       " 'Ly4': 0.8660254037844386,\n",
       " 'Lx5': 0.48784941439037594,\n",
       " 'Ly5': -0.8660254037844386}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow-gpu)",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
