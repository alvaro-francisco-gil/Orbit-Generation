{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "\n",
    "> Scripts to build the different datasets used for modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "#| hide\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Tuple, Optional, List, Dict\n",
    "from orbit_generation.data import load_orbit_data, get_orbit_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exact Periods with Time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All 5 periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_5p_em_dataset(data_directory: Optional[str] = '../data', \n",
    "                      output_file_path: Optional[str] = '../data/5p_dataset_em.npy') -> Tuple[np.memmap, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Load orbit data and corresponding labels. Optionally, save the loaded data.\n",
    "    If the output file exists, return the data as a memory-mapped array, otherwise process and save the data.\n",
    "    After saving, the data is also returned as a memory-mapped array.\n",
    "    \"\"\"\n",
    "    # Extract file extension to determine the type\n",
    "    _, file_extension = os.path.splitext(output_file_path)\n",
    "\n",
    "    # Validate supported file types\n",
    "    if file_extension not in ['.hdf5', '.npy']:\n",
    "        raise ValueError(\"Unsupported file extension. Supported extensions are '.hdf5' or '.npy'.\")\n",
    "\n",
    "    # Define the path for labels file\n",
    "    labels_path = f\"{os.path.splitext(output_file_path)[0]}_labels.npy\"\n",
    "\n",
    "    # Check if the combined data file already exists\n",
    "    if os.path.exists(output_file_path):\n",
    "        # Load data as memmap\n",
    "        data_memmap = np.load(output_file_path, mmap_mode='r+') if file_extension == '.npy' else None  # Add hdf5 handling if needed\n",
    "        labels_memmap = np.load(labels_path)\n",
    "        return data_memmap, labels_memmap\n",
    "\n",
    "    # Paths to data files\n",
    "    orbits_file_path = os.path.join(data_directory, \"em_orbits.h5\")\n",
    "    features_file_path = os.path.join(data_directory, \"em_features.mat\")\n",
    "\n",
    "    # Load orbit labels\n",
    "    labels_df = get_orbit_features(features_file_path, variable_name='out_EM') \n",
    "    labels = pd.Series(labels_df['Orbit Family']).repeat(5).reset_index(drop=True).to_numpy()\n",
    "\n",
    "    # Load orbit data\n",
    "    orbit_data = load_orbit_data(orbits_file_path, dataset_path='/files/PERIODIC ORBITS')\n",
    "    reshaped_array = orbit_data.reshape(36071, 7, 5, 1500)\n",
    "    orbit_data_final = reshaped_array.transpose(0, 2, 1, 3).reshape(36071 * 5, 7, 1500)\n",
    "\n",
    "    # Save the data if an output file path is provided\n",
    "    if file_extension == '.npy':\n",
    "        np.save(output_file_path, orbit_data_final)\n",
    "        np.save(labels_path, labels)\n",
    "        data_memmap = np.load(output_file_path, mmap_mode='r+')\n",
    "\n",
    "    return data_memmap, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_1p_em_dataset(data_directory: Optional[str] = '../data',\n",
    "                      output_file_path: Optional[str] = '../data/1p_dataset_em.npy') -> Tuple[np.memmap, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Load orbit data from an HDF5 file and corresponding labels from a MAT file, and optionally save the loaded data.\n",
    "    If the output file exists, it returns the data as a memory-mapped array. After saving, the data is also returned as a memory-mapped array.\n",
    "    \"\"\"\n",
    "    # Extract file extension to determine the type\n",
    "    _, file_extension = os.path.splitext(output_file_path)\n",
    "\n",
    "    # Validate supported file types\n",
    "    if file_extension not in ['.hdf5', '.npy']:\n",
    "        raise ValueError(\"Unsupported file extension. Supported extensions are '.hdf5' or '.npy'.\")\n",
    "\n",
    "    # Define the path for labels file\n",
    "    labels_path = f\"{os.path.splitext(output_file_path)[0]}_labels.npy\"\n",
    "\n",
    "    # Check if the combined data file already exists\n",
    "    if os.path.exists(output_file_path):\n",
    "        data_memmap = np.load(output_file_path, mmap_mode='r+') if file_extension == '.npy' else None\n",
    "        labels_memmap = np.load(labels_path)\n",
    "        return data_memmap, labels_memmap\n",
    "\n",
    "    # Paths to data files\n",
    "    orbits_file_path = os.path.join(data_directory, \"em_orbits.h5\")\n",
    "    features_file_path = os.path.join(data_directory, \"em_features.mat\")\n",
    "\n",
    "    # Load orbit labels\n",
    "    labels_df = get_orbit_features(features_file_path, variable_name='out_EM') \n",
    "    labels = labels_df['Orbit Family'].to_numpy()\n",
    "\n",
    "    # Load orbit data\n",
    "    orbit_data = load_orbit_data(orbits_file_path, dataset_path='/files/PERIODIC ORBITS')\n",
    "    reshaped_orbit_data = orbit_data[:, :, :1500]\n",
    "\n",
    "    # Save the data if an output file path is provided\n",
    "    if file_extension == '.npy':\n",
    "        np.save(output_file_path, reshaped_orbit_data)\n",
    "        np.save(labels_path, labels)\n",
    "        data_memmap = np.load(output_file_path, mmap_mode='r+')\n",
    "\n",
    "    return data_memmap, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific Period for each Orbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_sp_em_dataset(data_directory: Optional[str] = '../data', \n",
    "                      output_file_path: Optional[str] = '../data/sp_dataset_em.npy') -> Tuple[np.memmap, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Load orbit data and corresponding labels based on the specified number of periods per orbit.\n",
    "    If the output file exists, return the data as a memory-mapped array, otherwise process and save the data.\n",
    "    After saving, the data is also returned as a memory-mapped array.\n",
    "    \"\"\"\n",
    "    # Extract file extension to determine the type\n",
    "    _, file_extension = os.path.splitext(output_file_path)\n",
    "\n",
    "    # Validate supported file types\n",
    "    if file_extension not in ['.hdf5', '.npy']:\n",
    "        raise ValueError(\"Unsupported file extension. Supported extensions are '.hdf5' or '.npy'.\")\n",
    "\n",
    "    # Define the path for labels file\n",
    "    labels_path = f\"{os.path.splitext(output_file_path)[0]}_labels.npy\"\n",
    "\n",
    "    # Check if the combined data file already exists\n",
    "    if os.path.exists(output_file_path):\n",
    "        data_memmap = np.load(output_file_path, mmap_mode='r+') if file_extension == '.npy' else None\n",
    "        labels_memmap = np.load(labels_path)\n",
    "        return data_memmap, labels_memmap\n",
    "\n",
    "    # Paths to data files\n",
    "    orbits_file_path = os.path.join(data_directory, \"em_orbits.h5\")\n",
    "    features_file_path = os.path.join(data_directory, \"em_features.mat\")\n",
    "    periods_file_path = os.path.join(data_directory, \"em_periods.npy\")\n",
    "\n",
    "    # Load orbit labels\n",
    "    labels_df = get_orbit_features(features_file_path, variable_name='out_EM') \n",
    "    labels = labels_df['Orbit Family'].to_numpy()\n",
    "\n",
    "    # Load number of periods per orbit\n",
    "    periods_per_orbit = np.load(periods_file_path)\n",
    "\n",
    "    # Load orbit data\n",
    "    with h5py.File(orbits_file_path, 'r') as file:\n",
    "        orbit_data = np.array(file['/files/PERIODIC ORBITS'])\n",
    "\n",
    "    # Initialize the result array and label list\n",
    "    orbit_data_final = []\n",
    "    final_labels = []\n",
    "\n",
    "    # Iterate over the orbits and periods array\n",
    "    for index, num_periods in enumerate(periods_per_orbit):\n",
    "        for period_idx in range(num_periods):\n",
    "            start_idx = 1500 * period_idx\n",
    "            end_idx = start_idx + 1500\n",
    "            orbit_slice = orbit_data[index, :, start_idx:end_idx]\n",
    "            orbit_data_final.append(orbit_slice)\n",
    "            final_labels.append(labels[index])\n",
    "\n",
    "    # Convert list to numpy array\n",
    "    orbit_data_final = np.stack(orbit_data_final)  # This ensures a uniform 3D array\n",
    "\n",
    "    # Save the data if an output file path is provided\n",
    "    if file_extension == '.npy':\n",
    "        np.save(output_file_path, orbit_data_final)\n",
    "        np.save(labels_path, final_labels)\n",
    "        data_memmap = np.load(output_file_path, mmap_mode='r+')\n",
    "        final_labels = np.load(labels_path)\n",
    "\n",
    "    return data_memmap, final_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data, labels = get_sp_em_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fixed time step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specific Period for each Orbit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "include labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_sp_fixed_em_dataset(data_directory: Optional[str] = '../data', \n",
    "                            output_data_path: Optional[str] = '../data/em_periods.npy', \n",
    "                            output_periods_path: Optional[str] = '../data/em_periods.npy') -> Tuple[Dict[int, np.ndarray], np.ndarray]:\n",
    "    \"\"\"\n",
    "    Load orbit data from an HDF5 file.\n",
    "    \"\"\"\n",
    "\n",
    "    # Define the default data directory based on the script's location if not provided\n",
    "    if data_directory is None:\n",
    "        data_directory = os.path.join(os.path.dirname(__file__), \"Data\")\n",
    "    \n",
    "    # Define the file path for the orbit data\n",
    "    file_path = os.path.join(data_directory, \"em_orbits_dt_0_01.h5\")\n",
    "    \n",
    "    # Initialize a dictionary to hold data from all datasets\n",
    "    orbit_data = {}\n",
    "    \n",
    "    # Open the HDF5 file and read data from each dataset\n",
    "    with h5py.File(file_path, 'r') as file:\n",
    "        # Iterate through each dataset in the HDF5 file\n",
    "        for name in file:\n",
    "            dataset = np.array(file[name])\n",
    "            if name.isdigit():\n",
    "                orbit_data[int(name)] = dataset\n",
    "            else:\n",
    "                orbit_data[name] = dataset\n",
    "    \n",
    "    # Extract the periods\n",
    "    periods = orbit_data.get('prop_periods')[0] if 'prop_periods' in orbit_data else None\n",
    "\n",
    "    # Save the entire orbit data if an output path is provided\n",
    "    if output_data_path:\n",
    "        if output_data_path.endswith('.npy'):\n",
    "            np.save(output_data_path, orbit_data)\n",
    "        elif output_data_path.endswith('.h5'):\n",
    "            with h5py.File(output_data_path, 'w') as h5_file:\n",
    "                for key, data in orbit_data.items():\n",
    "                    h5_file.create_dataset(key, data=data)\n",
    "\n",
    "    # Save periods data if an output path is provided\n",
    "    if output_periods_path:\n",
    "        if output_periods_path.endswith('.npy'):\n",
    "            np.save(output_periods_path, periods)\n",
    "        elif output_periods_path.endswith('.h5'):\n",
    "            with h5py.File(output_periods_path, 'w') as h5_file:\n",
    "                h5_file.create_dataset('periods', data=periods)\n",
    "\n",
    "    return orbit_data, periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fixed_step_orbits(file_path: Optional[str] = 'your_file.hdf5'  # Path to the HDF5 file. Default is 'your_file.hdf5'.\n",
    "                         ) -> Tuple[Dict[int, np.ndarray],  # Dictionary of orbits with numerical keys.\n",
    "                                    pd.DataFrame,            # DataFrame containing orbit features.\n",
    "                                    Dict[str, float]]:       # Dictionary containing system features.\n",
    "    \"\"\"\n",
    "    Load orbit data from an HDF5 file.\n",
    "    \"\"\"\n",
    "    with h5py.File(file_path, 'r') as file:\n",
    "        # Extract not_propagated_orbits and store in a list of integers\n",
    "        not_propagated_orbits = [index - 1 for index in file['not_propagated_orbits'][0].tolist()]\n",
    "        \n",
    "        # Extract system features and labels\n",
    "        system_features = file['system_features'][:]\n",
    "        system_labels = file['system_labels'][:].astype(str)\n",
    "        \n",
    "        # Create a dictionary for system\n",
    "        system_dict = {label: feature[0] for label, feature in zip(system_labels.flatten().tolist(), system_features)}\n",
    "        \n",
    "        # Extract orbit features and labels\n",
    "        orbit_features = file['orbit_features'][:]\n",
    "        orbit_labels = file['orbit_labels'][:].astype(str)\n",
    "        \n",
    "        # Create a dataframe for orbits\n",
    "        orbit_df = pd.DataFrame(orbit_features.T, columns=orbit_labels.flatten().tolist())\n",
    "        \n",
    "        # Remove rows in orbit_df based on not_propagated_orbits\n",
    "        orbit_df = orbit_df.drop(not_propagated_orbits).reset_index(drop=True)\n",
    "        \n",
    "        # Extract numpy arrays with numerical keys\n",
    "        orbits = {int(key): file[key][:] for key in file.keys() if key.isdigit()}\n",
    "                \n",
    "    return orbits, orbit_df, system_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'your_file.hdf5' with the path to your .hdf5 file\n",
    "file_path = '/orbit-generation/data/orbits_dt_0_01/EM_dt_fix_0_01.h5'\n",
    "orbits, orbit_df, system_dict = get_fixed_step_orbits(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_class</th>\n",
       "      <th>x_0</th>\n",
       "      <th>y_0</th>\n",
       "      <th>x_0</th>\n",
       "      <th>vx_0</th>\n",
       "      <th>vy_0</th>\n",
       "      <th>vz_0</th>\n",
       "      <th>jacobi</th>\n",
       "      <th>period</th>\n",
       "      <th>stability</th>\n",
       "      <th>propagated_periods</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.004858</td>\n",
       "      <td>7.125289e-21</td>\n",
       "      <td>0.016846</td>\n",
       "      <td>-1.409706e-13</td>\n",
       "      <td>-0.019188</td>\n",
       "      <td>-2.276384e-13</td>\n",
       "      <td>2.999759</td>\n",
       "      <td>9.864033</td>\n",
       "      <td>58.026651</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.004856</td>\n",
       "      <td>7.127692e-21</td>\n",
       "      <td>0.016826</td>\n",
       "      <td>-1.353406e-13</td>\n",
       "      <td>-0.019194</td>\n",
       "      <td>-2.140871e-13</td>\n",
       "      <td>2.999760</td>\n",
       "      <td>9.859067</td>\n",
       "      <td>57.853541</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.004855</td>\n",
       "      <td>7.127904e-21</td>\n",
       "      <td>0.016806</td>\n",
       "      <td>-1.403916e-13</td>\n",
       "      <td>-0.019199</td>\n",
       "      <td>-2.306266e-13</td>\n",
       "      <td>2.999761</td>\n",
       "      <td>9.854100</td>\n",
       "      <td>57.681412</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.004854</td>\n",
       "      <td>7.128361e-21</td>\n",
       "      <td>0.016786</td>\n",
       "      <td>-1.410053e-13</td>\n",
       "      <td>-0.019205</td>\n",
       "      <td>-2.260639e-13</td>\n",
       "      <td>2.999761</td>\n",
       "      <td>9.849134</td>\n",
       "      <td>57.510259</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.004852</td>\n",
       "      <td>7.128849e-21</td>\n",
       "      <td>0.016766</td>\n",
       "      <td>-1.376750e-13</td>\n",
       "      <td>-0.019211</td>\n",
       "      <td>-2.215247e-13</td>\n",
       "      <td>2.999762</td>\n",
       "      <td>9.844167</td>\n",
       "      <td>57.340075</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id_class       x_0           y_0       x_0          vx_0      vy_0  \\\n",
       "0       1.0  1.004858  7.125289e-21  0.016846 -1.409706e-13 -0.019188   \n",
       "1       1.0  1.004856  7.127692e-21  0.016826 -1.353406e-13 -0.019194   \n",
       "2       1.0  1.004855  7.127904e-21  0.016806 -1.403916e-13 -0.019199   \n",
       "3       1.0  1.004854  7.128361e-21  0.016786 -1.410053e-13 -0.019205   \n",
       "4       1.0  1.004852  7.128849e-21  0.016766 -1.376750e-13 -0.019211   \n",
       "\n",
       "           vz_0    jacobi    period  stability  propagated_periods  \n",
       "0 -2.276384e-13  2.999759  9.864033  58.026651                 4.0  \n",
       "1 -2.140871e-13  2.999760  9.859067  57.853541                 4.0  \n",
       "2 -2.306266e-13  2.999761  9.854100  57.681412                 4.0  \n",
       "3 -2.260639e-13  2.999761  9.849134  57.510259                 4.0  \n",
       "4 -2.215247e-13  2.999762  9.844167  57.340075                 4.0  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orbit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39817, 11)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orbit_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39817"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(orbits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mu': 3.0542e-06,\n",
       " 'LU': 149597871.0,\n",
       " 'TU': 5022635.0,\n",
       " 'VU': 29.784738687959607,\n",
       " 'Lx1': 0.9899709220581561,\n",
       " 'Ly1': 0.0,\n",
       " 'Lx2': 1.0100904357842548,\n",
       " 'Ly2': 0.0,\n",
       " 'Lx3': -1.0000012725833332,\n",
       " 'Ly3': 0.0,\n",
       " 'Lx4': 0.4999969458,\n",
       " 'Ly4': 0.8660254037844386,\n",
       " 'Lx5': 0.4999969458,\n",
       " 'Ly5': -0.8660254037844386}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "system_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow-gpu)",
   "language": "python",
   "name": "tensorflow-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
