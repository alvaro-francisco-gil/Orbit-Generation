{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reader\n",
    "\n",
    "> Necessary scripts to read orbits from different formats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| export\n",
    "import h5py\n",
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from typing import Optional, Any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| export\n",
    "from unittest.mock import patch, MagicMock\n",
    "from fastcore.test import test_eq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def load_orbit_data(file_path: str,  # The path to the .mat, .h5, or .npy file.\n",
    "                    variable_name: Optional[str] = None,  # Name of the variable in the .mat file, optional.\n",
    "                    dataset_path: Optional[str] = None  # Path to the dataset in the .h5 file, optional.\n",
    "                   ) -> Any:  # The loaded orbit data.\n",
    "    \"\"\"\n",
    "    Load orbit data from MATLAB .mat files, HDF5 .h5 files, or NumPy .npy files.\n",
    "    \"\"\"\n",
    "    if file_path.endswith('.mat'):\n",
    "        if variable_name is None:\n",
    "            raise ValueError(\"variable_name must be provided for .mat files\")\n",
    "        mat = loadmat(file_path)\n",
    "        if variable_name in mat:\n",
    "            data = mat[variable_name]\n",
    "        else:\n",
    "            raise ValueError(f\"{variable_name} not found in {file_path}\")\n",
    "\n",
    "    elif file_path.endswith('.h5'):\n",
    "        with h5py.File(file_path, 'r') as file:\n",
    "            if dataset_path is None:\n",
    "                raise ValueError(\"dataset_path must be provided for .h5 files\")\n",
    "            if dataset_path in file:\n",
    "                data = np.array(file[dataset_path])\n",
    "            else:\n",
    "                raise ValueError(f\"{dataset_path} not found in {file_path}\")\n",
    "\n",
    "    elif file_path.endswith('.npy'):\n",
    "        data = np.load(file_path)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file format. Please provide a .mat, .h5, or .npy file.\")\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| test load_orbit_data\n",
    "#| hide\n",
    "mock_mat_data = {'Xarray': np.array([1, 2, 3])}\n",
    "mock_h5_data = np.array([4, 5, 6])\n",
    "mock_npy_data = np.array([7, 8, 9])\n",
    "\n",
    "# Test for load_orbit_data with .mat file\n",
    "with patch('__main__.loadmat', return_value=mock_mat_data) as mock_loadmat:\n",
    "    result = load_orbit_data('test_data.mat', variable_name='Xarray')\n",
    "    assert (result == mock_mat_data['Xarray']).all(), \"MAT file loading failed or data mismatch\"\n",
    "    mock_loadmat.assert_called_once_with('test_data.mat')\n",
    "\n",
    "# Test for load_orbit_data with .h5 file\n",
    "with patch('__main__.h5py.File') as mock_h5py:\n",
    "    mock_file = MagicMock()\n",
    "    mock_file.__enter__.return_value = {'/files/PERIODIC ORBITS': mock_h5_data}\n",
    "    mock_h5py.return_value = mock_file\n",
    "    result = load_orbit_data('test_data.h5', dataset_path='/files/PERIODIC ORBITS')\n",
    "    assert (result == mock_h5_data).all(), \"H5 file loading failed or data mismatch\"\n",
    "\n",
    "# Test for load_orbit_data with .npy file\n",
    "with patch('numpy.load', return_value=mock_npy_data) as mock_load:\n",
    "    result = load_orbit_data('test_data.npy')\n",
    "    assert (result == mock_npy_data).all(), \"NPY file loading failed or data mismatch\"\n",
    "    mock_load.assert_called_once_with('test_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_orbit_features(file_path: str,  # The path to the file (can be .mat, .h5, or .npy).\n",
    "                       variable_name: Optional[str] = None,  # Name of the variable in the .mat file, optional.\n",
    "                       dataset_path: Optional[str] = None  # Path to the dataset in the .h5 file, optional.\n",
    "                      ) -> pd.DataFrame:  # DataFrame with detailed orbit features.\n",
    "    \"\"\"\n",
    "    Load orbit feature data from a specified file and convert it to a DataFrame.\n",
    "    \"\"\"\n",
    "    # Load data using the previously defined function that supports .mat, .h5, and .npy files\n",
    "    orbit_data = load_orbit_data(file_path, variable_name=variable_name, dataset_path=dataset_path)\n",
    "    \n",
    "    # Define column labels for the DataFrame\n",
    "    column_labels = [\n",
    "        'Orbit Family', 'Initial Position X', 'Initial Position Y', 'Initial Position Z',\n",
    "        'Initial Velocity X', 'Initial Velocity Y', 'Initial Velocity Z',\n",
    "        'Jacobi Constant', 'Period', 'Stability Index'\n",
    "    ]\n",
    "    \n",
    "    # Create a DataFrame from the loaded data\n",
    "    features = pd.DataFrame(orbit_data, columns=column_labels)\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| test get_orbit_features\n",
    "#| hide\n",
    "def test_get_orbit_features():\n",
    "    # Sample data simulating what might be returned by load_orbit_data\n",
    "    mock_data = np.array([\n",
    "        [1, 0, 0, 0, 1, 0, 0, 3.0, 2.0, 1.0],\n",
    "        [2, 1, 1, 1, 0, 1, 0, 2.5, 1.5, 0.5]\n",
    "    ])\n",
    "    \n",
    "    # Expected DataFrame structure\n",
    "    expected_columns = [\n",
    "        'Orbit Family', 'Initial Position X', 'Initial Position Y', 'Initial Position Z',\n",
    "        'Initial Velocity X', 'Initial Velocity Y', 'Initial Velocity Z',\n",
    "        'Jacobi Constant', 'Period', 'Stability Index'\n",
    "    ]\n",
    "    expected_df = pd.DataFrame(mock_data, columns=expected_columns)\n",
    "    \n",
    "    # Patch the load_orbit_data function to return mock_data\n",
    "    with patch('__main__.load_orbit_data', return_value=mock_data) as mock_load_orbit_data:\n",
    "        # Test for .mat file\n",
    "        result_df = get_orbit_features('dummy_path.mat', variable_name='dummy_var')\n",
    "        test_eq(result_df.equals(expected_df), True)\n",
    "        \n",
    "        # Ensure the mock was called correctly\n",
    "        mock_load_orbit_data.assert_called_once_with('dummy_path.mat', variable_name='dummy_var', dataset_path=None)\n",
    "\n",
    "        # Test for .h5 file with dataset_path\n",
    "        mock_load_orbit_data.reset_mock()\n",
    "        result_df = get_orbit_features('dummy_path.h5', dataset_path='dummy_dataset')\n",
    "        test_eq(result_df.equals(expected_df), True)\n",
    "        \n",
    "        # Ensure the mock was called correctly\n",
    "        mock_load_orbit_data.assert_called_once_with('dummy_path.h5', variable_name=None, dataset_path='dummy_dataset')\n",
    "\n",
    "        # Test for .npy file\n",
    "        mock_load_orbit_data.reset_mock()\n",
    "        result_df = get_orbit_features('dummy_path.npy')\n",
    "        test_eq(result_df.equals(expected_df), True)\n",
    "        \n",
    "        # Ensure the mock was called correctly\n",
    "        mock_load_orbit_data.assert_called_once_with('dummy_path.npy', variable_name=None, dataset_path=None)\n",
    "\n",
    "# Call the test function to execute tests\n",
    "test_get_orbit_features()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_data(data: np.ndarray,  # The numpy array data to save.\n",
    "              file_name: str,  # The name of the file to save the data in.\n",
    "              file_type: str = 'hdf5'  # The type of file to save ('hdf5' or 'npy').\n",
    "             ) -> None:\n",
    "    \"\"\"\n",
    "    Save a numpy array to an HDF5 or a NumPy .npy file based on the specified file type.\n",
    "    \"\"\"\n",
    "    if file_type == 'hdf5':\n",
    "        # Open a new HDF5 file\n",
    "        with h5py.File(file_name, 'w') as f:\n",
    "            # Create a dataset in the file\n",
    "            f.create_dataset('orbit_data', data=data, compression='gzip', compression_opts=9)\n",
    "    elif file_type == 'npy':\n",
    "        # Save the array to a NumPy .npy file\n",
    "        np.save(file_name, data)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type specified. Use 'hdf5' or 'npy'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| test save_data\n",
    "#| hide\n",
    "# Test for NPY saving functionality\n",
    "def test_save_data_npy():\n",
    "    data = np.random.rand(5, 5)\n",
    "    file_name = 'test_data.npy'\n",
    "\n",
    "    with patch('numpy.save', autospec=True) as mock_save:\n",
    "        save_data(data, file_name, 'npy')\n",
    "        mock_save.assert_called_once_with(file_name, data)\n",
    "\n",
    "test_save_data_npy()\n",
    "\n",
    "# Test for handling invalid file type\n",
    "def test_save_data_invalid_type():\n",
    "    data = np.random.rand(5, 5)\n",
    "    file_name = 'test_data.unknown'\n",
    "\n",
    "    try:\n",
    "        save_data(data, file_name, 'unknown')\n",
    "        assert False, \"ValueError expected but not raised\"\n",
    "    except ValueError as e:\n",
    "        assert str(e) == \"Unsupported file type specified. Use 'hdf5' or 'npy'.\", \"Incorrect error message\"\n",
    "\n",
    "test_save_data_invalid_type()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Example Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_example_orbit_data():\n",
    "    \"\"\"\n",
    "    Load orbit data from a hardcoded MAT file located in the `data` directory.\n",
    "    \n",
    "    The function is specifically designed to load the 'Xarray' variable \n",
    "    from the '1_L2_S_200_EM_CR3BP.mat' file. This setup is intended for \n",
    "    demonstration or testing purposes, where the data file and the variable \n",
    "    of interest are known ahead of time.\n",
    "\n",
    "    :return: A numpy.ndarray containing the transposed data from the MAT file.\n",
    "    \"\"\"\n",
    "    # Hardcoded file name and variable name\n",
    "    filename = \"example_orbits_1_L2_S_200_EM_CR3BP.mat\"\n",
    "    variable_name = 'Xarray'\n",
    "    \n",
    "    # Assuming the notebook or script is executed in a directory at the same level as the `data` folder\n",
    "    matlab_file_path = '..' + \"/data/\" + filename\n",
    "    \n",
    "    # Assuming `load_orbit_data` is a predefined function that loads and returns data from the .mat file\n",
    "    data = load_orbit_data(str(matlab_file_path), variable_name=variable_name)\n",
    "    # Transpose the data for further use\n",
    "    data = np.transpose(data, (2, 1, 0))\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 6, 300)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_example_orbit_data()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "JSONDecodeError",
     "evalue": "Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#| hide\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnbdev\u001b[39;00m; \u001b[43mnbdev\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnbdev_export\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\anaconda3\\envs\\tsgm\\lib\\site-packages\\fastcore\\script.py:110\u001b[0m, in \u001b[0;36mcall_parse.<locals>._f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(func)\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_f\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    109\u001b[0m     mod \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39mgetmodule(inspect\u001b[38;5;241m.\u001b[39mcurrentframe()\u001b[38;5;241m.\u001b[39mf_back)\n\u001b[1;32m--> 110\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mod: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    111\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m SCRIPT_INFO\u001b[38;5;241m.\u001b[39mfunc \u001b[38;5;129;01mand\u001b[39;00m mod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m: SCRIPT_INFO\u001b[38;5;241m.\u001b[39mfunc \u001b[38;5;241m=\u001b[39m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(sys\u001b[38;5;241m.\u001b[39margv)\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m sys\u001b[38;5;241m.\u001b[39margv[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m: sys\u001b[38;5;241m.\u001b[39margv\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\alvar\\anaconda3\\envs\\tsgm\\lib\\site-packages\\nbdev\\doclinks.py:142\u001b[0m, in \u001b[0;36mnbdev_export\u001b[1;34m(path, procs, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m   procs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mgetattr\u001b[39m(nbdev\u001b[38;5;241m.\u001b[39mexport, p) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m L(procs)]\n\u001b[0;32m    141\u001b[0m files \u001b[38;5;241m=\u001b[39m nbglob(path\u001b[38;5;241m=\u001b[39mpath, as_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39msorted(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m--> 142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m files: \u001b[43mnb_export\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    143\u001b[0m add_init(get_config()\u001b[38;5;241m.\u001b[39mlib_path)\n\u001b[0;32m    144\u001b[0m _build_modidx()\n",
      "File \u001b[1;32mc:\\Users\\alvar\\anaconda3\\envs\\tsgm\\lib\\site-packages\\nbdev\\export.py:67\u001b[0m, in \u001b[0;36mnb_export\u001b[1;34m(nbname, lib_path, procs, debug, mod_maker, name)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lib_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: lib_path \u001b[38;5;241m=\u001b[39m get_config()\u001b[38;5;241m.\u001b[39mlib_path\n\u001b[0;32m     66\u001b[0m exp \u001b[38;5;241m=\u001b[39m ExportModuleProc()\n\u001b[1;32m---> 67\u001b[0m nb \u001b[38;5;241m=\u001b[39m \u001b[43mNBProcessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mexp\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43mL\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprocs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdebug\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdebug\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     68\u001b[0m nb\u001b[38;5;241m.\u001b[39mprocess()\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m mod,cells \u001b[38;5;129;01min\u001b[39;00m exp\u001b[38;5;241m.\u001b[39mmodules\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32mc:\\Users\\alvar\\anaconda3\\envs\\tsgm\\lib\\site-packages\\nbdev\\process.py:93\u001b[0m, in \u001b[0;36mNBProcessor.__init__\u001b[1;34m(self, path, procs, nb, debug, rm_directives, process)\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, path\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, procs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, nb\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, debug\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, rm_directives\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, process\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnb \u001b[38;5;241m=\u001b[39m \u001b[43mread_nb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m nb \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m nb\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlang \u001b[38;5;241m=\u001b[39m nb_lang(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnb)\n\u001b[0;32m     95\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m cell \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnb\u001b[38;5;241m.\u001b[39mcells: cell\u001b[38;5;241m.\u001b[39mdirectives_ \u001b[38;5;241m=\u001b[39m extract_directives(cell, remove\u001b[38;5;241m=\u001b[39mrm_directives, lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlang)\n",
      "File \u001b[1;32mc:\\Users\\alvar\\anaconda3\\envs\\tsgm\\lib\\site-packages\\execnb\\nbio.py:57\u001b[0m, in \u001b[0;36mread_nb\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_nb\u001b[39m(path):\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReturn notebook at `path`\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 57\u001b[0m     res \u001b[38;5;241m=\u001b[39m dict2nb(\u001b[43m_read_json\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     58\u001b[0m     res[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpath_\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(path)\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32mc:\\Users\\alvar\\anaconda3\\envs\\tsgm\\lib\\site-packages\\execnb\\nbio.py:16\u001b[0m, in \u001b[0;36m_read_json\u001b[1;34m(self, encoding, errors)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_json\u001b[39m(\u001b[38;5;28mself\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m---> 16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\alvar\\anaconda3\\envs\\tsgm\\lib\\json\\__init__.py:357\u001b[0m, in \u001b[0;36mloads\u001b[1;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m kw[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    355\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[0;32m    356\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[1;32m--> 357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m JSONDecoder\n",
      "File \u001b[1;32mc:\\Users\\alvar\\anaconda3\\envs\\tsgm\\lib\\json\\decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[1;34m(self, s, _w)\u001b[0m\n\u001b[0;32m    332\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, s, _w\u001b[38;5;241m=\u001b[39mWHITESPACE\u001b[38;5;241m.\u001b[39mmatch):\n\u001b[0;32m    333\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[0;32m    334\u001b[0m \u001b[38;5;124;03m    containing a JSON document).\u001b[39;00m\n\u001b[0;32m    335\u001b[0m \n\u001b[0;32m    336\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 337\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    338\u001b[0m     end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n\u001b[0;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m end \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(s):\n",
      "File \u001b[1;32mc:\\Users\\alvar\\anaconda3\\envs\\tsgm\\lib\\json\\decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[1;34m(self, s, idx)\u001b[0m\n\u001b[0;32m    353\u001b[0m     obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscan_once(s, idx)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[1;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
